{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Linear Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will develop a model to estimate price of house given the following parameters\n",
    " -  Size\n",
    " -  No. of Bedrooms\n",
    " -  No. of Bathrooms\n",
    " -  Distance to City\n",
    " -  Age of House\n",
    " -  School Quality\n",
    "\n",
    "For the model I will be using a training set of 1000 records generated from AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression Model\n",
    "\n",
    "The equation of the linear regression model is given by:\n",
    "\n",
    "$$ f(x_{1},x_{2},....,x_{n}) = \\sum \\limits _{i=1} ^{n} w_{i}x_{i}\\:+\\:B $$\n",
    "\n",
    "Where:\n",
    "- $f(x_{1},x_{2},....,x_{n})$ is the prediction of the model ( $ \\hat{Y} $ ) for given set of inputs\n",
    "- n is the no. of independent variables\n",
    "- $x_{i}$ is the independent variable\n",
    "- $B$ is the y-intercept\n",
    "- $w_{i}$ is the slope of the line with respect to $x_{i}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Function\n",
    "\n",
    "Equation of the model should give good approxiamtion for the given inputs. Therefore we use least squares approach to ensure our models gives better approximation for the given inputs.<br> \n",
    "Cost function gives normalized value for sum of squares of error generated by model for known output values.\n",
    "\n",
    "$$ J(w,b) = \\frac{1}{2m} \\sum \\limits _{i=1} ^{m} [f(x_{1},x_{2},....,x_{n})-y_{i}]^2 $$\n",
    "\n",
    "Where :\n",
    " - $m$ is the no. of training examples\n",
    " - $y_{i}$ is the actual output of for given set of inputs \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_func(X,W,B):\n",
    "    '''\n",
    "    This function returns the output of the model\n",
    "        X: input data as a numpy 2D array\n",
    "        W: Weights as a numpy array\n",
    "        B: Bias\n",
    "    '''\n",
    "    Y_hat=np.dot(X,W)+B\n",
    "    return Y_hat\n",
    "\n",
    "def cost_func(Y_hat,Y):\n",
    "    '''\n",
    "    This function returns the cost of the model\n",
    "        input_data: input data as a 2-D numpy array\n",
    "        output_data: output data as a numpy array\n",
    "    '''\n",
    "    return np.mean((Y_hat - Y)**2)/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we need to find $w_{i},B$ for $f$ minimize the cost functions. lower the value of cost function is, better the approximation of the model gets.<br>\n",
    "By differentiating $J(w,B)$ with respect to the parameters and equating it to zero we can have a set of simultaneous equations which can be solved to find the parameters.<br>\n",
    "For data sets with large number of inputs it could get complex to solve the set of simultaneous equations. So here we use ___gradient descent algorithm___ which is an _iteretive technique_ to find $w,B$<br>\n",
    "\n",
    "$$ w_{n} = w_{n-1}-\\alpha \\frac {\\partial{J(w,B)}}{\\partial{w}} $$ \n",
    "$$B_{n} = B_{n-1}-\\alpha \\frac {\\partial{J(w,B)}}{\\partial{B}}$$\n",
    "\n",
    "\n",
    "$\\frac {\\displaystyle\\partial{J(w,B)}}{\\displaystyle\\partial{w_{k}}} = \\sum \\limits _{i=1} ^{m} [w_{1}x_{i,1}+w_{2}x_{i,2}+...+w_{k}x_{i,k}+...+w_{n}x_{i,n}+B-y_{i}] \\frac {x_{k}}{m}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def para_update(X,Y,W,B,alpha,error):\n",
    "    '''\n",
    "    This function updates the parameters of the model\n",
    "        X: input data as a numpy array\n",
    "        Y: output data as a numpy array\n",
    "        W: Weights as a numpy array\n",
    "        B: Bias\n",
    "        alpha: learning rate\n",
    "        error : allowed relative error\n",
    "    '''\n",
    "\n",
    "    Y_hat = model_func(X,W,B)\n",
    "    Wn = W - alpha*np.dot(X,(Y_hat - Y))\n",
    "    Bn = B - alpha*np.sum(Y_hat - Y)\n",
    "    rel_error_w = np.max(np.abs(Wn-W))/np.max(np.abs(W))\n",
    "    rel_error_b=abs(Bn/B-1)\n",
    "    if rel_error_w<error and rel_error_b<error:\n",
    "        return Wn,Bn\n",
    "    else:\n",
    "        return para_update(X,Y,Wn,Bn,alpha,error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Parameters for the Data set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14 20 26]\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataScience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
